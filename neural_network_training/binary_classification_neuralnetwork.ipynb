{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff3946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all relavent libraries, not some are not used \n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d94bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of training files, toy files are provided on the repo.\n",
    "data_directory = \"\" #use if training files are in the same folder as this code \n",
    "signals = np.load(data_directory + \"./psd_data.npy\") #includes PSD graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b9e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_amplitude = 1e-22\n",
    "#each data segment corresponds to sampling frequency 100Hz for 30 seconds\n",
    "num_datapoints = int(30*100)\n",
    "gaussian_noise = np.random.normal(0, noise_amplitude, (len(signals), num_datapoints))\n",
    "\n",
    "psd_noise = sig.welch(gaussian_noise, fs = 100)[1][:, :20]\n",
    "#normalize as with previous\n",
    "noises = np.log10(psd_noise)\n",
    "assert(len(noises) == len(signals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f0d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([signals, noises])\n",
    "labels = np.hstack([np.ones( (len(signals), ) ), np.zeros( (len(noises), ) )])\n",
    "\n",
    "#shuffle in unison\n",
    "p = np.random.permutation(len(data))\n",
    "data = data[p]\n",
    "labels_s = labels[p]\n",
    "params = np.expand_dims(labels_s, axis = 1) #formatting for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb4f0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val, -45.579468922452655\n"
     ]
    }
   ],
   "source": [
    "#normalizing by average value, make sure to maintain this value for pipeline code\n",
    "print(\"avg val,\", np.average(data))\n",
    "data -= np.average(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9aa5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network hyperparameters\n",
    "batch_size = 20\n",
    "input_shape = (20,)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d33b3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95000, 20):xtrain, (5000, 20):xtest, (95000, 1):ytrain, (5000, 1):ytest\n"
     ]
    }
   ],
   "source": [
    "split = 95000\n",
    "test_split = split\n",
    "x_train = data[:split, :]\n",
    "x_test = data[test_split:, :]\n",
    "\n",
    "y_train = params[:split, :]\n",
    "y_test = params[test_split:, :]\n",
    "\n",
    "print(\"{}:xtrain, {}:xtest, {}:ytrain, {}:ytest\".\n",
    "      format(x_train.shape, x_test.shape, y_train.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "443fa8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,121,729\n",
      "Trainable params: 2,121,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#define neural network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1024, activation = 'relu', \n",
    "                input_shape = input_shape))\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e54b31dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4750/4750 [==============================] - 31s 6ms/step - loss: 5.6150e-04 - accuracy: 0.9998 - val_loss: 6.1770e-34 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "4750/4750 [==============================] - 30s 6ms/step - loss: 5.2729e-15 - accuracy: 1.0000 - val_loss: 6.1770e-34 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "4750/4750 [==============================] - 32s 7ms/step - loss: 1.6867e-16 - accuracy: 1.0000 - val_loss: 6.1770e-34 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "4750/4750 [==============================] - 32s 7ms/step - loss: 1.6121e-14 - accuracy: 1.0000 - val_loss: 6.1460e-34 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "4750/4750 [==============================] - 32s 7ms/step - loss: 3.9046e-14 - accuracy: 1.0000 - val_loss: 5.9048e-34 - val_accuracy: 1.0000\n",
      "Test loss: 5.904803375300498e-34\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#compile model with relevant loss, optimizer, and metric\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#fit to the training data\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "#evaluate the preformance on the testing set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model to relevant location, will need this for the pipeline simulation\n",
    "model_save_directory = \"\" #save model to same the same folder as this program\n",
    "model.save(\"./binary_classification_network.h5\", include_optimizer = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
